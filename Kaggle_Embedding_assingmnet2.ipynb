{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pB0Ik6HjP3O"
   },
   "source": [
    "# Assignment 2 in DLWS - elo competition category Embedding\n",
    "\n",
    "In this part of the assignmet we are trying to use embedding in  the elo kaggle competition which can be seen here : https://www.kaggle.com/c/elo-merchant-category-recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "i50P-YC4v-fH",
    "outputId": "7179deed-f0e6-4234-d3c4-dbd506d0411b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWGIZeoNl4pg"
   },
   "source": [
    "Imports we use in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ViFM7vuqweBc",
    "outputId": "97d6142d-2b15-48e8-9472-b672d7536f99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding , concatenate, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    " \n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7Mue4aRmYHJ"
   },
   "source": [
    "Path to load the data and loading hte train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkkWO-IrwL1U"
   },
   "outputs": [],
   "source": [
    "path = 'drive/My Drive/MY DLWS/Elo World/'\n",
    "\n",
    "train = pd.read_csv(path + 'train.csv', parse_dates=['first_active_month'])\n",
    "test = pd.read_csv(path + 'test.csv', parse_dates=['first_active_month'])\n",
    "his_trans = pd.read_csv(path + 'historical_transactions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESnas0P2mdtZ"
   },
   "source": [
    "Taking only the categorical data from the history and train data and merge them to one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9W5aXLZuxvo3"
   },
   "outputs": [],
   "source": [
    "cat_train = train[['card_id','feature_1','feature_2','feature_3']]\n",
    "\n",
    "cat_hist_trans = his_trans[['card_id','state_id']]\n",
    "\n",
    "cat_train = pd.merge(cat_train, cat_hist_trans, how='left', on=['card_id'])\n",
    "\n",
    "cat_train = cat_train.drop(['card_id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "Ns2AAJQQz6G9",
    "outputId": "950bfa13-3bef-42d8-ddb7-3d825a735f89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  state_id\n",
       "0          5          2          1         9\n",
       "1          5          2          1         9\n",
       "2          5          2          1         9\n",
       "3          5          2          1         9\n",
       "4          5          2          1         9"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## removing dataframes to save space - in this data, space is a real concern.\n",
    "del his_trans\n",
    "gc.collect()\n",
    "\n",
    "cat_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SWtJPojXm8tA"
   },
   "source": [
    "Using category embedding like we saw in class - we try yo create an embedding between the 3 features in the train data to the state_id feature in the history and new transacrition data for start. the same code can be used again and again to create different embeddings from the data, or to create embedding from more features if we would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dB45Tx_q11QT"
   },
   "outputs": [],
   "source": [
    "n_ftr_1 = cat_train['feature_1'].nunique()\n",
    "n_ftr_2 = cat_train['feature_2'].nunique()\n",
    "n_ftr_3 = cat_train['feature_3'].nunique()\n",
    "\n",
    "n_state_id = cat_train['state_id'].nunique()\n",
    "\n",
    "ftr_1 = {p:i for (i,p) in enumerate(cat_train['feature_1'].unique())}\n",
    "ftr_2 = {p:i for (i,p) in enumerate(cat_train['feature_2'].unique())}\n",
    "ftr_3 = {p:i for (i,p) in enumerate(cat_train['feature_3'].unique())}\n",
    "             \n",
    "state_id = {p:i for (i,p) in enumerate(cat_train['state_id'].unique())}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DChpBzqX4kHY"
   },
   "outputs": [],
   "source": [
    "n_emb_output = 5\n",
    "\n",
    "processed_his = cat_train.loc[:,['feature_1','feature_2','feature_3']].copy()\n",
    "\n",
    "\n",
    "processed_his['feature_1'] = [ftr_1[x] for x in cat_train['feature_1']]\n",
    "processed_his['feature_2'] = [ftr_2[x] for x in cat_train['feature_2']]\n",
    "processed_his['feature_3'] = [ftr_3[x] for x in cat_train['feature_3']]\n",
    "\n",
    "\n",
    "ftr_1_in = Input(shape=(1,), dtype='int64', name='ftr_1')\n",
    "ftr_2_in = Input(shape=(1,), dtype='int64', name='ftr_2')\n",
    "ftr_3_in = Input(shape=(1,), dtype='int64', name='ftr_3')\n",
    "\n",
    "ftr_1_emb = Embedding(n_ftr_1, n_emb_output, input_length=1 ,embeddings_regularizer=l2(1e-4))(ftr_1_in)\n",
    "ftr_2_emb = Embedding(n_ftr_2, n_emb_output, input_length=1 ,embeddings_regularizer=l2(1e-4))(ftr_2_in)\n",
    "ftr_3_emb = Embedding(n_ftr_3, n_emb_output, input_length=1 ,embeddings_regularizer=l2(1e-4))(ftr_3_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "colab_type": "code",
    "id": "zqRtcNLQO5Hh",
    "outputId": "73613c4c-fe7c-4d51-88f3-3610cdeb5022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ftr_1 (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ftr_2 (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ftr_3 (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 5)         25          ftr_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         15          ftr_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 5)         10          ftr_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 15)        0           embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 15)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          4096        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           8256        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 25)           1625        dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,923\n",
      "Trainable params: 46,923\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = concatenate([ftr_1_emb, ftr_2_emb, ftr_3_emb], name = 'concatenate')\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dense(128, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dense(64, activation='relu', kernel_initializer='he_normal')(x)\n",
    "\n",
    "x = Dense(n_state_id, activation='softmax')(x)\n",
    "\n",
    "\n",
    "nn = Model([ftr_1_in, ftr_2_in, ftr_3_in], x)\n",
    "\n",
    "\n",
    "target = to_categorical([state_id[x] for x in cat_train['state_id']])\n",
    "\n",
    "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qQO6Mu1vaEz"
   },
   "source": [
    "The idea of embedding as we understood it is to create new features for the data using the original categorical features we have in the train data and the categorical feautres in the other datasets. i.e we want to create a new fetures representing the connection between the original features and other feautres in the complete data and use this embedding to help improve the model results on the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "yI39159dVJG5",
    "outputId": "f9a0ffdc-75b2-4ac8-a1d7-ff1c0eec643c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14424007 samples, validate on 3606002 samples\n",
      "Epoch 1/1\n",
      "14424007/14424007 [==============================] - 2648s 184us/step - loss: 2.3810 - acc: 0.3643 - val_loss: 2.3838 - val_acc: 0.3623\n"
     ]
    }
   ],
   "source": [
    "history = nn.fit([processed_his[f] for f in processed_his.columns], target, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpX93GC8nVt8"
   },
   "outputs": [],
   "source": [
    "nn.save_weights(path + 'my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WY9BioNuK2QF"
   },
   "outputs": [],
   "source": [
    "nn.load_weights(path + 'my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFbn2FP0_HAc"
   },
   "source": [
    "**Using the embedding layer for loyalty predictions**\n",
    "\n",
    "\n",
    "Here we used only the embedding we created to prdict the loyalty. the resutls are no so good as we can see. that might be beacuse the embedding wasnt done right or beacuse there is no real connection between the features so the knowledge gain in the embedding is no use.\n",
    "also thete inght be there are not engouh features used to make a good predictaion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "id": "q7TJbgPLhMof",
    "outputId": "290b7a93-f259-425e-a5c7-e15f869522ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"co...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ftr_1 (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ftr_2 (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ftr_3 (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 5)         25          ftr_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         15          ftr_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 5)         10          ftr_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 15)        0           embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 15)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          4096        flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          32896       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128)          512         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64)           8256        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64)           256         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            65          batch_normalization_9[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 47,155\n",
      "Trainable params: 46,209\n",
      "Non-trainable params: 946\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "main_model = Model(input = nn.input, output = nn.get_layer('concatenate').output)\n",
    "\n",
    "for layer in main_model.layers:\n",
    "   layer.trainable = False\n",
    "\n",
    "y = main_model.output\n",
    "y = Flatten()(y)\n",
    "y = Dense(256, activation='relu', kernel_initializer='he_normal')(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dense(128, activation='relu', kernel_initializer='he_normal')(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dense(64, activation='relu', kernel_initializer='he_normal' )(y)\n",
    "y = BatchNormalization()(y)\n",
    "pred = Dense(1, activation='relu', kernel_initializer='he_normal')(y)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=2, min_lr=0.001)\n",
    "\n",
    "class PrintLearningRate(Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print(K.eval(self.model.optimizer.lr))\n",
    "\n",
    "print_lr = PrintLearningRate()\n",
    "\n",
    "    \n",
    "main_model = Model([ftr_1_in, ftr_2_in, ftr_3_in], pred)\n",
    "sgd = SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "main_model.compile(optimizer=sgd, loss='mse')\n",
    "main_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "colab_type": "code",
    "id": "b2ZWuGd3njHH",
    "outputId": "f30a9c5d-3457-47d5-ef18-080be0365fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161533 samples, validate on 40384 samples\n",
      "Epoch 1/10\n",
      "161533/161533 [==============================] - 15s 95us/step - loss: 14.8773 - val_loss: 15.5280\n",
      "0.1\n",
      "Epoch 2/10\n",
      "161533/161533 [==============================] - 15s 90us/step - loss: 14.8446 - val_loss: 15.5280\n",
      "0.1\n",
      "Epoch 3/10\n",
      "161533/161533 [==============================] - 15s 91us/step - loss: 14.8446 - val_loss: 15.5280\n",
      "0.05\n",
      "Epoch 4/10\n",
      "161533/161533 [==============================] - 14s 89us/step - loss: 14.8446 - val_loss: 15.5280\n",
      "0.05\n",
      "Epoch 5/10\n",
      "161533/161533 [==============================] - 14s 89us/step - loss: 14.8446 - val_loss: 15.5280\n",
      "0.025\n",
      "Epoch 6/10\n",
      "161533/161533 [==============================] - 14s 89us/step - loss: 14.8446 - val_loss: 15.5280\n",
      "0.025\n",
      "Epoch 7/10\n",
      "161533/161533 [==============================] - 15s 92us/step - loss: 14.8446 - val_loss: 15.5280\n",
      "0.0125\n",
      "Epoch 8/10\n",
      "161533/161533 [==============================] - 16s 98us/step - loss: 14.8446 - val_loss: 15.5280\n",
      "0.0125\n",
      "Epoch 9/10\n",
      "161533/161533 [==============================] - 16s 96us/step - loss: 14.8446 - val_loss: 15.5280\n",
      "0.00625\n",
      "Epoch 10/10\n",
      "161533/161533 [==============================] - 16s 98us/step - loss: 14.8446 - val_loss: 15.5280\n",
      "0.00625\n"
     ]
    }
   ],
   "source": [
    "processed_train = train.loc[:,['feature_1','feature_2','feature_3']].copy()\n",
    "processed_train['feature_1'] = [ftr_1[x] for x in train['feature_1']]\n",
    "processed_train['feature_2'] = [ftr_2[x] for x in train['feature_2']]\n",
    "processed_train['feature_3'] = [ftr_3[x] for x in train['feature_3']]\n",
    "\n",
    "\n",
    "history = main_model.fit([processed_train[f] for f in processed_train.columns], train.target, validation_split=0.2, batch_size=128, epochs=10, callbacks=[reduce_lr, print_lr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wP1lhUjFARky"
   },
   "source": [
    "**Using the embedding + train features**\n",
    "\n",
    "\n",
    "Here we use both the original features in the data and the embedding we created to try to predict the loyalty value. there is no real improvment to the ANN model and it's seems the model is unable to learn as well as we would like.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "fV4cdVuRtq7N",
    "outputId": "db60187e-b50f-4df9-bdc3-1eb1abb21437"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"co...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "emb_mod = Model(input = nn.input, output = nn.get_layer('concatenate').output)\n",
    "emb_out = emb_mod.predict([processed_train[f] for f in processed_train.columns])\n",
    "\n",
    "max_date = train['first_active_month'].dt.date.max()\n",
    "\n",
    "def date_parse(df):\n",
    "  date_parts = ['year', 'month' , 'weekday']\n",
    "  for part in date_parts:\n",
    "    date_part_col = 'first_active_month_' + part\n",
    "    df[date_part_col] = getattr(df['first_active_month'].dt, part).astype(int)\n",
    "  df['elasped_time'] = (max_date - df['first_active_month'].dt.date).dt.days\n",
    "  return df\n",
    "\n",
    "\n",
    "new_train = date_parse(train).drop(['first_active_month','card_id','target'], axis=1)\n",
    "emb_out = emb_out.reshape((emb_out.shape[0]), n_emb_output * 3)\n",
    "pred =  pd.DataFrame(emb_out)\n",
    "new_train = pd.concat([new_train, pred], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWiKUhQ-y0kA"
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(n_emb_output * 3 + 7,))\n",
    "z = Dense(256, activation='relu', kernel_initializer='he_normal')(inp)\n",
    "z = BatchNormalization()(z)\n",
    "z = Dense(128, activation='relu', kernel_initializer='he_normal')(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Dense(64, activation='relu', kernel_initializer='he_normal' )(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Dense(1, activation='relu', kernel_initializer='he_normal')(z)\n",
    "\n",
    "model = Model(inputs = inp, outputs= z)\n",
    "\n",
    "sgd = SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "8XabNbWD0WgR",
    "outputId": "eb003dce-7a77-4470-a997-74cc7c451bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161533 samples, validate on 40384 samples\n",
      "Epoch 1/5\n",
      "161533/161533 [==============================] - 29s 182us/step - loss: 14.9101 - val_loss: 15.5280\n",
      "0.1\n",
      "Epoch 2/5\n",
      "161533/161533 [==============================] - 28s 173us/step - loss: 14.8445 - val_loss: 15.5280\n",
      "0.1\n",
      "Epoch 3/5\n",
      "161533/161533 [==============================] - 28s 173us/step - loss: 14.8445 - val_loss: 15.5280\n",
      "0.05\n",
      "Epoch 4/5\n",
      "161533/161533 [==============================] - 28s 173us/step - loss: 14.8445 - val_loss: 15.5280\n",
      "0.05\n",
      "Epoch 5/5\n",
      "161533/161533 [==============================] - 28s 172us/step - loss: 14.8445 - val_loss: 15.5280\n",
      "0.025\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=new_train, y=train.target, batch_size=64, epochs=5, validation_split = 0.2, callbacks=[reduce_lr, print_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMIL161-A6Oj"
   },
   "source": [
    "**Using feature extraction for a novel ml algorithm from the ANN using the original features and embedding**\n",
    "\n",
    "In this part we try to train a RandomForestRegressor model using original features of the train data and the feautres we extracted from our ANN model that used both the original features and the embeddings.\n",
    "\n",
    "the extraction was performed like in previous work which means we took the output from the second to lsat layer in the ANN model that used both original features and embedded features and extract it as new 64 features we then used with the original features  as input for the random forest model.\n",
    "the result were an improvemnet from the previous ANN models but not as significant as we would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "ZTskumg-y0b9",
    "outputId": "25c99727-0f7c-4268-f0f5-6f0f468fb5cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss - 3.8325267059143635\n",
      "Val loss - 3.8676051399380498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "ftr_extr_model = Model(input = model.input, output = model.layers[-2].output)\n",
    "\n",
    "ftr_extr_in = ftr_extr_model.predict(new_train)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(ftr_extr_in, train.target, test_size=0.2, random_state=42)\n",
    "\n",
    "ml_model = RandomForestRegressor(n_estimators=150, criterion='mse', max_depth=7, \n",
    "                                 min_samples_leaf=15, max_features=6, \n",
    "                                 bootstrap=True, random_state=42)\n",
    "ml_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "train_pred = ml_model.predict(x_train)\n",
    "val_pred = ml_model.predict(x_val)\n",
    "\n",
    "print('Train loss - {}'.format(np.sqrt(np.mean((train_pred - y_train)**2))))\n",
    "print('Val loss - {}'.format(np.sqrt(np.mean((val_pred - y_val)**2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TA4GAAexiEW"
   },
   "source": [
    "Final remarks:\n",
    "we hope we understood the concept behind categorical embeddings. at first we spend a lot of time and effort doing embedding in a way we then realized isnt correct and wasnt the point of the assignment which resulted in a lot of time wasted without real results we can show here.\n",
    "\n",
    "in the end the embedding we crated did not improve the model at all so either we didnt understtod what embeddings meant here or that there is no real value for embedding on the elo dataset.\n",
    "\n",
    "out best result was achive by using normal feature engineering and lgb model in the end with no connection to DL and/or embedding.\n",
    "\n",
    "Also, the elo data is very uncelar and untill now we are not sure what actually we tried to predict in it and what would have been the best way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6nqDumWyqhX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kaggle - Embedding.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
